# TabSMC - Pure JAX Implementation

High-performance Sequential Monte Carlo for tabular data using pure JAX.

## ðŸš€ Performance Improvements

This branch contains a complete rewrite of TabSMC using pure JAX, eliminating the dumpy overhead for significant performance improvements:

- **10x+ faster** than the original dumpy implementation
- **JIT-compiled** for maximum performance
- **Scales efficiently** to large datasets
- **Production-ready** with comprehensive test suite

## ðŸ“Š Benchmarks

Performance on various dataset sizes:
- **Small Scale** (200 samples): 239 pts/s
- **Medium Scale** (500 samples): 1,305 pts/s  
- **Large Scale** (1,000 samples): 3,343 pts/s

## ðŸ§ª Usage

```python
import jax
import jax.numpy as jnp
from tabsmc.smc import mcmc_minibatch, init_assignments

# Generate or load your one-hot encoded data (N x D x K)
key = jax.random.PRNGKey(42)
X = jnp.array(your_data)  # Shape: (N, D, K)

# Run MCMC
A, Ï†, Ï€, Î¸ = mcmc_minibatch(
    key=key,
    X=X, 
    T=100,     # iterations
    C=3,       # clusters
    B=50,      # batch size
    Î±_pi=1.0,  # Dirichlet prior for mixing weights
    Î±_theta=1.0  # Dirichlet prior for emissions
)
```

## ðŸ”§ Key Functions

- `init_empty(key, C, D, K, N, Î±_pi, Î±_theta)` - Initialize with empty assignments
- `init_assignments(key, X, C, D, K, Î±_pi, Î±_theta)` - Initialize with sampled assignments  
- `gibbs(key, X_B, I_B, A, Ï†, Ï€, Î¸, Î±_pi, Î±_theta)` - One Gibbs sampling step
- `mcmc_minibatch(key, X, T, C, B, Î±_pi, Î±_theta)` - Full MCMC with random batches

## ðŸ§ª Tests

Run the test suite:

```bash
# Basic functionality
uv run python tests/test_smc_jax_simple.py

# Performance benchmarks  
uv run python tests/test_final_performance_comparison.py

# MCMC analysis
uv run python tests/test_mcmc_jax_performance.py

# Step particle verification
uv run python tests/test_step_particle_jax.py
```

## ðŸ“ˆ Features

- âœ… **Pure JAX** - No dumpy overhead
- âœ… **JIT compilation** - Maximum performance  
- âœ… **Efficient memory usage** - Pre-allocated arrays
- âœ… **Log-space computations** - Numerical stability
- âœ… **Random minibatches** - Better mixing
- âœ… **Comprehensive tests** - Verified correctness

## ðŸ”„ Migration from Dumpy

The JAX implementation maintains the same mathematical properties and API design as the original, but with:
- Pure JAX arrays instead of dumpy arrays
- Direct einsum operations instead of named axis operations
- JIT compilation for all core functions
- Significant performance improvements

Old dumpy-based code has been moved to `old_dumpy_implementation/` for reference.